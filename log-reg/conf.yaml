use_smote: True
valratio_clients: 0.1

num_rounds: [20]
num_clients: [5, 10, 20]

dataset:
  location: diabetes/diabetes.csv
  target: Diabetes_binary

# currentData = DatasetLoader('diabetes/diabetes.csv', 'Diabetes_binary')
# currentData = DatasetLoader('fetal_health/fetal_health.csv', 'fetal_health')
# currentData = DatasetLoader('datasets/heart2/framingham.csv', 'TenYearCHD')
#dataset:
#  location: datasets/covid-19/covid_19.csv
#  target: RESULTADO
# currentData = DatasetLoader('datasets/covid-19/covid_19.csv', 'RESULTADO')

model:
  penalty: [l1] #, l2]
  max_iter: [10] #, 10, 50, 100, 400]
  solver: [liblinear]
  tol:  [0.001] #, 0.001, 0.0001, 0.00001, 0.000001]
  C: [0.75] #, 0.35, 0.5, 1, 2, 5, 10]
  warm_start: [True]
  epsilon: [0.5] # [0.01, 0.05, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0] # Controls the privacy loss; smaller values mean stronger privacy.
  delta: [0.000001] # [0.1, 0.01, 0.001, 0.0001, 0.00001] # Controls the probability of the privacy guarantee being broken; smaller values mean stronger privacy.

# every strategy has a name (by which it gets selected in the code, e.g. 'fedavg') 
# and a unique set of hyperparameters (over which it can gridsearch) (goal 150-300 runs)
strategies:
  strategy_opt: #fedOpt 243 runs NOG UITZOEKEN
     name: FedOpt
     eta: [0.3, 0.2, 0.1] #[0.1, 0.3, 0.01] #[0.3, 0.1, 0.01] # server-side learningrate. defaults to 0.1
     eta_l: [0.2, 0.1, 0.05] #[0.01, 0.3] #[0.3, 0.1, 0.01] # client-side learningrate. defaults to 0.1
     beta_1: [0.95, 0.9, 0.5] # momentum parameter. defaults to 0.9
     beta_2: [0.999, 0.99] #[0.99, 0.999, 0.9] # [0.999, 0.99, 0.9] # second momentum parameter. Defaults to 0.99
     tau: [0.00000001, 0.000000001, 0.0000000001] # [0.00000001, 0.000000001, 0.0000000001] # server-side learningrate decay. defaults to 0.000000001

  strategy5: #fedavgm
   name: FedAvgM
   server_learning_rate: [1.1, 1.0, 0.9] #[1.0, 1.0, 0.003, 1.0, 1.0, 0.3, 1.0, 1, 3] # [3.0, 2.0, 1.0, 0.7, 0.3] # [1.0] # [1.0, 0.1, 0.01, 0.001] # server-side learningrate. defaults to 1.0
   server_momentum: [0, 0.001, 0.01, 0.1] #[0, 0, 0.99, 0, 0, 0.1, 0, 0, 0.6] #[0, 0.1, 0.2, 0.3, 0.4] #[0.0] # [0.0, 0.9, 0.99] # server-side momentum. defaults to 0.0

  #strategy6: #FedTrimmedAvg
  #   name: FedTrimmedAvg
  #   beta: #[0.25, 0.25, 0.15, 0.45, 0.35, 0,3, 0.5, 0.2, 0.3] #[0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5] #[0.2] # [0.1, 0.2, 0.3, 0.4, 0.5] # fraction to cut off of both tails of the distribution. Defaults to 0.2

  strategy7: #fedprox all over the place, another search doenst contribute.
   name: FedProx
   proximal_mu: [0.00001, 0.01, 1.0, 0.00001, 1.0, 0.00000001, 1.0, 1.0, 0.01] #[1.0, 0.3, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001] # [0.1, 0.01, 0.001] # proximal term. Defaults to 0.1. 0.0 would be equal to fedavg

unchosen_strategies_2nd_run: #did not contain a run above 0.5
  strategy_adagrad: # fedadagrad 72 runs
    name: FedAdagrad
    eta: [0.001, 0.3, 0.1] # server-side learningrate. defaults to 0.1
    eta_l: [0.3, 0.03, 0.001, 0.01] # client-side learningrate. defaults to 0.1
    tau: [0.0000000005, 0.0000000003, 0.0000000002, 0.0000000001, 0.00000000003, 0.00000000001] # server-side learningrate decay. defaults to 0.000000001

  strategy_adam: # fedadam 108 runs
    name: FedAdam
    eta: [0.3, 0.01] # server-side learningrate. defaults to 0.1
    eta_l: [0.1, 0.3, 0.01] # client-side learningrate. defaults to 0.1
    beta_1: [0.95, 0.5] # momentum parameter. defaults to 0.9
    beta_2: [0.99, 0.999, 0.9] # second momentum parameter. Defaults to 0.99
    tau: [0.00000001, 0.000000001, 0.0000000001] # server-side learningrate decay. defaults to 0.000000001

  strategy_yogi: #fedyogi 243 runs
    name: FedYogi
    eta: [0.003, 0.001, 0.0003, 0.0001] # [0.1, 0.01, 0.001] # server-side learningrate. defaults to 0.01
    eta_l: [0.03, 0.003, 0.3] #[0.3, 0.03, 0.003] # client-side learningrate. defaults to 0.0316
    beta_1: [0.95, 0.9] #[0.95, 0.9, 0.5] # momentum parameter. defaults to 0.9
    beta_2: [0.99, 0.999, 0.9] # [0.999, 0.99, 0.9] #second momentum parameter. Defaults to 0.99
    tau: [0.001, 0.0001] #[0.01, 0.001, 0.0001] # controls the degree of adaptability. defaults to 0.001


  strategy1: # fedavg
    name: FedAvg
    lr: [ 0.003, 0.001, 0.0003, 0.0001, 0.00003, 0.00001] #[0.01, 0.001, 0.0001, 0.00001]
    momentum: [0.6, 0.8, 0.4, 0.1] #[0.9, 0.5, 0.1]

  strategy5: #fedavgm
   name: FedAvgM
   server_learning_rate: [3.0, 2.0, 1.0, 0.7, 0.3] # [1.0] # [1.0, 0.1, 0.01, 0.001] # server-side learningrate. defaults to 1.0
   server_momentum: [0, 0.1, 0.2, 0.3, 0.4] #[0.0] # [0.0, 0.9, 0.99] # server-side momentum. defaults to 0.0

  strategy6: #FedTrimmedAvg
     name: FedTrimmedAvg
     beta: [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5] #[0.2] # [0.1, 0.2, 0.3, 0.4, 0.5] # fraction to cut off of both tails of the distribution. Defaults to 0.2

  strategy7: #fedprox
   name: FedProx
   proximal_mu: [1.0, 0.3, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001] # [0.1, 0.01, 0.001] # proximal term. Defaults to 0.1. 0.0 would be equal to fedavg

  strategy8: #fedMedian
   name: FedMedian

debugging:
  client: False
  datasets: False
  main: False
  mia: False
  model: False
  plot: False
  save: False
  server: False

# used in attack-missed.py
missed-folders:
  foldername1: results/2024-09-15
  foldername2: results/2024-09-16